# Music Genre Classification Using Acoustic Features and Autoencoders (2021)
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9598979

* using digital signal processing techniques and autoencoders
* GTZAN dataset has been used.
* Aim is to compare the digital signal processing technique to using autoencoders.
* To train the autoencoder - Mel Frequency Cepstral Coefficients (MFCC) are used
* * https://medium.com/prathena/the-dummys-guide-to-mfcc-aceab2450fd
* The autoencoder is a CNN (which they describe in Figure 1)
* They use the latent space representation (ie the bit between the encoder and decoder) to classify and cluster
* "Therefore it is seen that using just autoencoder has not made any improvement rather it gives less accuracy"

* Essentially they're trying to see if you can use the features picked out by an autoencoder to classify the music, and they find that no this is not possible even with latent spaces of varying sizes.
* They did reference the 2020 Elbir paper for a similar technique

# Music Genre Classification using Machine Learning Techniques
https://arxiv.org/pdf/1804.01149.pdf

*
*

# Music genre classification and music recommendation by using deep learning (2020 - Elbir)
https://ietresearch.onlinelibrary.wiley.com/doi/epdf/10.1049/el.2019.4202

*
*
